{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b055cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the modeules we've used before\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import rdkit\n",
    "# Render the figure in a notebook:\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f958b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nan0_xtest = pd.read_csv('X_testNan1scaled_Desc.csv', index_col=0)\n",
    "Nan0_xtrain = pd.read_csv('X_trainNan1scaled_Desc.csv', index_col=0)\n",
    "Nan0_xval = pd.read_csv('X_valNan1scaled_Desc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4c0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nan0_ytest = pd.read_csv('y_testNan1.csv', index_col=0)\n",
    "Nan0_ytrain = pd.read_csv('y_trainNan1.csv', index_col=0)\n",
    "Nan0_yval = pd.read_csv('y_valNan1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a78263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "num_rows_with_nan = Nan0_xtrain.isna().any(axis=1).sum()\n",
    "print(num_rows_with_nan)\n",
    "### Nan exist in desc. dataframe, need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6681ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan0_xtest.isna().stack()[lambda x: x].index\n",
    "# Nan0_xtest.index[Nan0_xtest.isna().any(axis=1)]\n",
    "\n",
    "# rows, cols = np.where(Nan0_xtest.isna())\n",
    "\n",
    "# for r, c in zip(rows, cols):\n",
    "#     print(f\"NaN at row={Nan0_xtest.index[r]}, column={Nan0_xtest.columns[c]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fa2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Nan0_xtrain.notna().all(axis=1)\n",
    "\n",
    "Nan0_xtrain_clean = Nan0_xtrain[mask]\n",
    "Nan0_ytrain_clean = Nan0_ytrain[mask]\n",
    "\n",
    "mask2 = Nan0_xtest.notna().all(axis=1)\n",
    "\n",
    "Nan0_xtest_clean = Nan0_xtest[mask2]\n",
    "Nan0_ytest_clean = Nan0_ytest[mask2]\n",
    "\n",
    "mask3 = Nan0_xval.notna().all(axis=1)\n",
    "\n",
    "Nan0_xval_clean = Nan0_xval[mask3]\n",
    "Nan0_yval_clean = Nan0_yval[mask3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1caf6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_rows_with_nan_clean = Nan0_xtrain_clean.isna().any(axis=1).sum()\n",
    "print(num_rows_with_nan_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ded79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4fe83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9340f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define a XGBC Model for Optimisation\n",
    "XGBC = XGBClassifier(\n",
    "    eta=0.3,\n",
    "    gamma=0,\n",
    "    max_depth=6,\n",
    "    subsample=1,\n",
    "    min_child_weight=1,\n",
    "    objective='binary:logistic',   # binary classification\n",
    "    eval_metric='logloss'          # or 'auc'\n",
    ")\n",
    "\n",
    "XGBC.fit (Nan0_xtrain_clean, Nan0_ytrain_clean)\n",
    "y_pred = XGBC.predict(Nan0_xtest_clean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a90979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "Best balanced accuracy: 0.6531999512262697\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now optimise it using GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"learning_rate\": [0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Grid search with 5-fold CV\n",
    "grid = GridSearchCV(XGBC, param_grid, cv=5, scoring=\"balanced_accuracy\")\n",
    "grid.fit(Nan0_xtrain_clean, Nan0_ytrain_clean)\n",
    "\n",
    "# Best parameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best balanced accuracy:\", grid.best_score_)\n",
    "\n",
    "# Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
    "# Best CV accuracy: 0.7171948233076011\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c237a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6468411996066863\n"
     ]
    }
   ],
   "source": [
    "#Now run the pipeline with the optimised model#######################16/12/2025 Ends Here!!!\n",
    "XGBC_op = XGBClassifier(\n",
    "    n_estimators = 100,\n",
    "    eta=0.1,\n",
    "    gamma=0,\n",
    "    max_depth=6,\n",
    "    subsample=1,\n",
    "    min_child_weight=1,\n",
    "    objective='binary:logistic',   # binary classification\n",
    "    eval_metric='logloss'          # or 'auc'\n",
    ")\n",
    "\n",
    "XGBC_op.fit (Nan0_xtrain_clean, Nan0_ytrain_clean)\n",
    "y_pred_op = XGBC_op.predict(Nan0_xtest_clean)\n",
    "\n",
    "print(\"Accuracy:\", balanced_accuracy_score(Nan0_ytest_clean, y_pred_op))\n",
    "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix(Nan0_ytest_clean, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c5c655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9200297776299224, 0.9635388739946381, 0.9465367395312089, 0.9549621363092866, 0.637195292017627, 0.8540609137055838, 0.7613122171945701, 0.8050239234449761]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def get_model_metrics(fitted_model, x_train, x_val, y_train, y_val):\n",
    "    pred_X_train = fitted_model.predict(x_train)\n",
    "    pred_X_val = fitted_model.predict(x_val)\n",
    "    train_bal_acc = metrics.balanced_accuracy_score(y_train, pred_X_train)\n",
    "    val_bal_acc = metrics.balanced_accuracy_score(y_val, pred_X_val)\n",
    "    train_recall = metrics.recall_score(y_train, pred_X_train)\n",
    "    val_recall = metrics.recall_score(y_val, pred_X_val)\n",
    "    train_precision = metrics.precision_score(y_train, pred_X_train)\n",
    "    val_precision = metrics.precision_score(y_val, pred_X_val)\n",
    "    train_f1 = metrics.f1_score(y_train, pred_X_train)\n",
    "    val_f1 = metrics.f1_score(y_val, pred_X_val)\n",
    "    metric_list = [train_bal_acc, train_recall, train_precision, train_f1, val_bal_acc, val_recall, val_precision, val_f1]\n",
    "    print(metric_list)\n",
    "\n",
    "get_model_metrics(XGBC_op, Nan0_xtrain_clean, Nan0_xval_clean, Nan0_ytrain_clean, Nan0_yval_clean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9a993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_phenol_noOrthoHbond</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_alkyl_halide</td>\n",
       "      <td>0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_benzene</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr_phenol</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_NH0</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr_aniline</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fr_bicyclic</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fr_ether</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fr_Al_COO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fr_Al_OH_noTert</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fr_Ar_COO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fr_Ar_NH</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fr_Ar_OH</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fr_COO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fr_COO2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fr_C_S</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fr_HOCCN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fr_Imine</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fr_NH1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fr_NH2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fr_N_O</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fr_Ndealkylation1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fr_Ndealkylation2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fr_Nhpyrrole</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fr_aldehyde</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "0   fr_phenol_noOrthoHbond    0.004167\n",
       "1          fr_alkyl_halide    0.003535\n",
       "2               fr_benzene    0.002778\n",
       "3                fr_phenol    0.001514\n",
       "4                   fr_NH0    0.001389\n",
       "5               fr_aniline    0.001389\n",
       "6              fr_bicyclic    0.001389\n",
       "7                 fr_ether    0.001389\n",
       "8                fr_Al_COO    0.000000\n",
       "9          fr_Al_OH_noTert    0.000000\n",
       "10               fr_Ar_COO    0.000000\n",
       "11                fr_Ar_NH    0.000000\n",
       "12                fr_Ar_OH    0.000000\n",
       "13                  fr_COO    0.000000\n",
       "14                 fr_COO2    0.000000\n",
       "15                  fr_C_S    0.000000\n",
       "16                fr_HOCCN    0.000000\n",
       "17                fr_Imine    0.000000\n",
       "18                  fr_NH1    0.000000\n",
       "19                  fr_NH2    0.000000\n",
       "20                  fr_N_O    0.000000\n",
       "21       fr_Ndealkylation1    0.000000\n",
       "22       fr_Ndealkylation2    0.000000\n",
       "23            fr_Nhpyrrole    0.000000\n",
       "24             fr_aldehyde    0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "baseline = balanced_accuracy_score(\n",
    "    Nan0_ytest_clean,\n",
    "    XGBC_op.predict(Nan0_xtest_clean) #calculates a balanced accuracy score using the optimised model\n",
    ")\n",
    "\n",
    "importances = [] #empty list generation\n",
    "\n",
    "for col in Nan0_xtest_clean.columns:\n",
    "    X_perm = Nan0_xtest_clean.copy() #makes a copy of the df\n",
    "    X_perm[col] = np.random.permutation(X_perm[col]) #goes through the columns in the copied df and shuffles the features\n",
    "\n",
    "    score = balanced_accuracy_score(\n",
    "        Nan0_ytest_clean,\n",
    "        XGBC_op.predict(X_perm)\n",
    "    ) #calculates a balanced accuracy score with shuffled features\n",
    "\n",
    "    importances.append(baseline - score) #subtracts the scores the larger the performance drop and the output the more important the feature\n",
    "\n",
    "importances = pd.DataFrame(importances)\n",
    "\n",
    "importances\n",
    "\n",
    "importances_df = pd.DataFrame({\n",
    "    \"feature\": Nan0_xtest_clean.columns,\n",
    "    \"importance\": importances[0]   # your single-column DataFrame\n",
    "})\n",
    "\n",
    "# Get the top 25 features\n",
    "fr_features = importances_df[importances_df[\"feature\"].str.startswith(\"fr_\")]\n",
    "\n",
    "# Get top 25\n",
    "top25_fr = fr_features.nlargest(25, \"importance\").reset_index(drop=True)\n",
    "\n",
    "top25_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61507c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
